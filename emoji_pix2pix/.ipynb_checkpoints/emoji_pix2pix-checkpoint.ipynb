{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH, CHANNEL = 64, 64, 3\n",
    "BATCH_SIZE = 64\n",
    "EPS = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgpath = 'RGB_emoji/'\n",
    "sketchpath = 'canny/'\n",
    "testpath = 'testimg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lrelu(x, n, leak=0.2): \n",
    "    return tf.maximum(x, leak * x, name=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_train_data():\n",
    "    \n",
    "    images = glob.glob(imgpath+'*.jpg')\n",
    "    images.sort()\n",
    "    sketches = glob.glob(sketchpath+'*.jpg')\n",
    "    sketches.sort()\n",
    "    \n",
    "    # print images    \n",
    "    all_images = tf.convert_to_tensor(images, dtype = tf.string)\n",
    "    all_sketches = tf.convert_to_tensor(sketches, dtype = tf.string)\n",
    "    \n",
    "    \n",
    "    images_queue = tf.train.slice_input_producer([all_images,all_sketches],shuffle=False)\n",
    "                                        \n",
    "    img_content = tf.read_file(images_queue[0])\n",
    "    image = tf.image.decode_jpeg(img_content, channels = CHANNEL)\n",
    "    \n",
    "    sketch_content = tf.read_file(images_queue[1])\n",
    "    sketch = tf.image.decode_jpeg(sketch_content, channels = CHANNEL)\n",
    "        \n",
    "    size = [HEIGHT, WIDTH]\n",
    "    \n",
    "    image = tf.image.resize_images(image, size)\n",
    "    image.set_shape([HEIGHT,WIDTH,CHANNEL])\n",
    "    \n",
    "    sketch = tf.image.resize_images(sketch, size)\n",
    "    sketch.set_shape([HEIGHT,WIDTH,CHANNEL])\n",
    "    \n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = ((image / 255.0)-0.5)*2\n",
    "    \n",
    "    sketch = tf.cast(sketch, tf.float32)\n",
    "    sketch = ((sketch / 255.0)-0.5)*2\n",
    "    \n",
    "    images_batch,sketches_batch = tf.train.shuffle_batch(\n",
    "                                    [image,sketch], batch_size = BATCH_SIZE,\n",
    "                                    num_threads = 4, capacity = 200 + 3* BATCH_SIZE,\n",
    "                                    min_after_dequeue = 200)\n",
    "    num_images = len(images)\n",
    "\n",
    "    return images_batch,sketches_batch,num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    \n",
    "    batch_size = 1\n",
    "    sketches = glob.glob(testpath+'*.jpg')\n",
    "    sketches.sort()\n",
    "    \n",
    "    all_sketches = tf.convert_to_tensor(sketches, dtype = tf.string)\n",
    "    \n",
    "    \n",
    "    images_queue = tf.train.slice_input_producer([all_sketches],shuffle=False)\n",
    "    \n",
    "    sketch_content = tf.read_file(images_queue[0])\n",
    "    sketch = tf.image.decode_jpeg(sketch_content, channels = CHANNEL)\n",
    "    \n",
    "    size = [HEIGHT, WIDTH]\n",
    "\n",
    "    sketch = tf.image.resize_images(sketch, size)\n",
    "    sketch.set_shape([HEIGHT,WIDTH,CHANNEL])\n",
    "    \n",
    "    sketch = tf.cast(sketch, tf.float32)\n",
    "    sketch = ((sketch / 255.0)-0.5)*2\n",
    "    \n",
    "    test_batch = tf.train.shuffle_batch(\n",
    "                                    [sketch], batch_size = batch_size,\n",
    "                                    num_threads = 1, capacity = 200 + 3* batch_size,\n",
    "                                    min_after_dequeue = 200)\n",
    "\n",
    "    return test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generator(input, is_train, keep_prob,reuse=False):\n",
    "    c0, c1, c2, c3, c4 = 8, 16, 32, 64,128\n",
    "    output_dim = CHANNEL  # RGB image\n",
    "    with tf.variable_scope('gen') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "            \n",
    "            \n",
    "        # encode: intput :64x64x3\n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv0 = tf.layers.conv2d(input, c0, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv0')\n",
    "        bn0 = tf.contrib.layers.batch_norm(conv0, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn0')\n",
    "        act0 = lrelu(bn0, n='act0')\n",
    "        # output :32x32x8\n",
    "        \n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv1 = tf.layers.conv2d(act0, c1, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv1')\n",
    "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn1')\n",
    "        act1 = lrelu(bn1, n='act1')\n",
    "        # output :16x16x16\n",
    "        \n",
    "        \n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv2 = tf.layers.conv2d(act1, c2, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv2')\n",
    "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "        act2 = lrelu(bn2, n='act2')\n",
    "                \n",
    "        # output :8x8x32\n",
    "        \n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv3 = tf.layers.conv2d(act2, c3, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv3')\n",
    "        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
    "        act3 = lrelu(bn3, n='act3')\n",
    "        \n",
    "        # output :4x4x64\n",
    "        \n",
    "        \n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv4 = tf.layers.conv2d(act3, c4, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv4')\n",
    "        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
    "        act4 = lrelu(bn4, n='act4')\n",
    "        \n",
    "        #output: 2x2x128\n",
    "        \n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv5 = tf.layers.conv2d(act4, c4, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv5')\n",
    "        bn5 = tf.contrib.layers.batch_norm(conv5, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn5')\n",
    "        act5 = lrelu(bn5, n='act5')\n",
    "        \n",
    "        #output:1x1x128\n",
    "        \n",
    "        # decode\n",
    "        #Convolution, bias, activation, repeat! \n",
    "        dconv0 = tf.layers.conv2d_transpose(act5, c4, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='dconv0')\n",
    "        dbn0 = tf.contrib.layers.batch_norm(dconv0, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='dbn0')\n",
    "        dact0 = tf.nn.relu(dbn0, name='dact0')\n",
    "        \n",
    "        #output: 2x2x128\n",
    "        merge_0 = tf.concat([dact0, act4], axis=3)\n",
    "        # output: 2x2x256\n",
    "        \n",
    "        dconv1 = tf.layers.conv2d_transpose(merge_0, c3, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='dconv1')\n",
    "        dbn1 = tf.contrib.layers.batch_norm(dconv1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='dbn1')\n",
    "        dact1 = tf.nn.relu(dbn1, name='dact1')\n",
    "        #output: 4x4x64\n",
    "        \n",
    "        dact1 = tf.nn.dropout(dact1, keep_prob)\n",
    "        \n",
    "        merge_1 = tf.concat([dact1, act3], axis=3)\n",
    "        #output: 4x4x128\n",
    "                \n",
    "        \n",
    "        dconv2 = tf.layers.conv2d_transpose(merge_1, c2, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='dconv2')\n",
    "        dbn2 = tf.contrib.layers.batch_norm(dconv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='dbn2')\n",
    "        dact2 = tf.nn.relu(dbn2, name='dact2')\n",
    "                \n",
    "        # output: 8x8x32\n",
    "        dact2 = tf.nn.dropout(dact2, keep_prob)\n",
    "        \n",
    "        merge_2 = tf.concat([dact2, act2], axis=3)\n",
    "        #output: 8x8x64\n",
    "        \n",
    "        \n",
    "        dconv3 = tf.layers.conv2d_transpose(merge_2, c1, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='dconv3')\n",
    "        dbn3 = tf.contrib.layers.batch_norm(dconv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='dbn3')\n",
    "        dact3 = tf.nn.relu(dbn3, name='dact3')\n",
    "        # output: 16x16x16\n",
    "        dact3 = tf.nn.dropout(dact3, keep_prob)\n",
    "        \n",
    "        merge_3 = tf.concat([dact3, act1], axis=3)\n",
    "        #output: 16x16x32\n",
    "        \n",
    "        dconv4 = tf.layers.conv2d_transpose(merge_3, c0, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='dconv4')\n",
    "        dbn4 = tf.contrib.layers.batch_norm(dconv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='dbn4')\n",
    "        dact4 = tf.nn.relu(dbn4, name='dact4')\n",
    "        # output: 32x32x8\n",
    "        dact4 = tf.nn.dropout(dact4, keep_prob)\n",
    "        \n",
    "        merge_4 = tf.concat([dact4, act0], axis=3)\n",
    "        #output: 32x32x16\n",
    "        \n",
    "        dconv5 = tf.layers.conv2d_transpose(merge_4, 3, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv9')\n",
    "        #output: 64x64x3\n",
    "        \n",
    "        \n",
    "        \n",
    "        dact5 = tf.nn.tanh(dconv5, name='dact5')\n",
    "                \n",
    "        return dact5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def discriminator(inputs, targets, is_train, reuse=False):\n",
    "    c0,c1, c2, c3, c4 = 8, 16, 32, 64, 128  # channel num: 32,64, 128, 256, 512\n",
    "    with tf.variable_scope('dis') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "            \n",
    "        input = tf.concat([inputs, targets], axis=3)\n",
    "        \n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv0 = tf.layers.conv2d(input, c0, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv0')\n",
    "        \n",
    "        bn0 = tf.contrib.layers.batch_norm(conv0, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn0')\n",
    "        act0 = lrelu(bn0, n='act0')\n",
    "        \n",
    "        #output: 32x32x8\n",
    "        \n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv1 = tf.layers.conv2d(act0, c1, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv1')\n",
    "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn1')\n",
    "\n",
    "        act1 = lrelu(bn1, n='act1')\n",
    "        \n",
    "        # output: 16x16x16\n",
    "        \n",
    "         #Convolution, activation, bias, repeat! \n",
    "        conv2 = tf.layers.conv2d(act1, c2, kernel_size=[3, 3], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv2')\n",
    "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "\n",
    "        act2 = lrelu(bn2, n='act2')\n",
    "        \n",
    "        # output: 8x8x32\n",
    "        \n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv3 = tf.layers.conv2d(act2, c3, kernel_size=[3, 3], strides=[1, 1], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv3')\n",
    "        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
    "        act3 = lrelu(bn3, n='act3')\n",
    "        \n",
    "        # output: 8x8x64\n",
    "        \n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv4 = tf.layers.conv2d(act3, c4, kernel_size=[3, 3], strides=[1, 1], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv4')\n",
    "        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
    "        act4 = lrelu(bn4, n='act4')\n",
    "        \n",
    "        # output: 8x8x128\n",
    "        \n",
    "         #Convolution, activation, bias, repeat! \n",
    "        conv5 = tf.layers.conv2d(act4, 1, kernel_size=[3, 3], strides=[1, 1], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv5')\n",
    "        act5 = tf.nn.sigmoid(conv5, name='act5')\n",
    "        \n",
    "        # output: 8x8x1\n",
    "\n",
    "        \n",
    "        return act5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('input'):\n",
    "    #real and fake image placholders\n",
    "    sketch_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='sketch_image')\n",
    "    real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n",
    "    is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "    keep_prob = tf.placeholder(tf.float32,name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_image = generator(sketch_image, is_train,keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_result = discriminator(sketch_image,real_image, is_train)\n",
    "fake_result = discriminator(sketch_image,trans_image ,is_train, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_loss = tf.reduce_mean(-(tf.log(real_result + EPS) + tf.log(1 - fake_result + EPS))) # This optimizes the discriminator.\n",
    "\n",
    "g_loss_pred = tf.reduce_mean(-tf.log(fake_result + EPS))  # This optimizes the generator.\n",
    "g_loss_L1 = tf.reduce_mean(tf.abs(real_image - trans_image))\n",
    "g_loss = g_loss_pred + g_loss_L1*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_vars = tf.trainable_variables()\n",
    "d_vars = [var for var in t_vars if 'dis' in var.name]\n",
    "g_vars = [var for var in t_vars if 'gen' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer_d = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(d_loss, var_list=d_vars)\n",
    "trainer_g = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "image_batch,sketch_batch,samples_num = process_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_num = int(samples_num / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_path = 'model/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "log_path = 'logs/'\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)\n",
    "\n",
    "example_path = 'example/'\n",
    "if not os.path.exists(example_path):\n",
    "    os.makedirs(example_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_iters = 5\n",
    "g_iters = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer_d_loss = tf.summary.FileWriter(log_path+'d_loss',sess.graph)\n",
    "    writer_g_loss = tf.summary.FileWriter(log_path+'g_loss')\n",
    "\n",
    "    loss_var = tf.Variable(0.0)\n",
    "    tf.summary.scalar(\"loss\", loss_var)\n",
    "    write_op = tf.summary.merge_all()\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    start = 0\n",
    "    ckpt = tf.train.latest_checkpoint(save_path)\n",
    "    if ckpt:\n",
    "        print 'restore:'+str(ckpt)\n",
    "        saver.restore(sess, ckpt)\n",
    "        start = int(ckpt.split('-')[-1])+1\n",
    "        \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    for step in range(start,EPOCH*batch_num):\n",
    "        \n",
    "        train_image,train_sketch =  sess.run([image_batch,sketch_batch])\n",
    "        \n",
    "        \n",
    "        for j in range(1):\n",
    "            \n",
    "            for k in range(d_iters):\n",
    "                _, dLoss = sess.run([trainer_d, d_loss],\n",
    "                                    feed_dict={sketch_image: train_sketch, real_image: train_image, is_train: True, keep_prob:0.999})\n",
    "            if d_iters!=0:\n",
    "                print 'dLoss:'+str(dLoss)\n",
    "\n",
    "\n",
    "            for k in range(g_iters):\n",
    "                _, gLoss = sess.run([trainer_g, g_loss],\n",
    "                                    feed_dict={sketch_image: train_sketch,real_image: train_image, is_train: True, keep_prob:0.999})\n",
    "            \n",
    "            if g_iters!=0:\n",
    "                print 'gLoss:'+str(gLoss)\n",
    "        \n",
    "            \n",
    "                \n",
    "        if step%25 == 0:\n",
    "            saver.save(sess, save_path + 'model.ckpt', global_step=step)\n",
    "            \n",
    "            if d_iters!=0:\n",
    "                summary = sess.run(write_op, {loss_var: dLoss})\n",
    "                writer_d_loss.add_summary(summary, step)\n",
    "                writer_d_loss.flush()\n",
    "            if g_iters!=0:\n",
    "                summary = sess.run(write_op, {loss_var: gLoss})\n",
    "                writer_g_loss.add_summary(summary, step)\n",
    "                writer_g_loss.flush()\n",
    "            \n",
    "        if step%25 == 0:\n",
    "            # sample_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            imgtest = sess.run(trans_image, feed_dict={sketch_image: train_sketch, is_train: False,keep_prob:1})\n",
    "            save_images(imgtest, [8,8] , example_path+'step_' + str(step) + '.jpg')\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    \n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    test_batch = process_test_data()\n",
    "\n",
    "    with tf.variable_scope('input'):\n",
    "        sketch_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='sketch_image')\n",
    "        real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n",
    "        is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "        keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "    \n",
    "    trans_image = generator(sketch_image, is_train,keep_prob)\n",
    "    real_result = discriminator(sketch_image,real_image, is_train)\n",
    "    fake_result = discriminator(sketch_image,trans_image ,is_train, reuse=True)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "        \n",
    "    save_path = 'model/'\n",
    "    \n",
    "    gen_path = 'testgen/'\n",
    "    if not os.path.exists(gen_path):\n",
    "        os.makedirs(gen_path)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        ckpt = tf.train.latest_checkpoint(save_path)    \n",
    "        saver.restore(sess, ckpt)\n",
    "        \n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "        test_sketch =  sess.run([test_batch])\n",
    "        \n",
    "\n",
    "        generate_img = sess.run(trans_image, feed_dict={sketch_image: test_sketch[0], is_train: False,keep_prob: 1})\n",
    "        \n",
    "        save_img = np.ones(shape=(2,64,64,3),dtype=np.float32)\n",
    "        \n",
    "        save_img[0] = test_sketch[0]\n",
    "        save_img[1] = generate_img\n",
    "                \n",
    "        save_images(save_img, [2,1] , gen_path+ str(random.randint(1,200)) + '.jpg')\n",
    "        \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
